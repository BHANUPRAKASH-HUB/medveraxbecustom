{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56869aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded dataset: (99620, 10)\n",
      "‚úÖ Group-wise split completed\n",
      "Train size: (97231, 5)\n",
      "Test size : (2389, 5)\n",
      "\n",
      "üöÄ Training logistic_regression\n",
      "Metrics: {'model': 'logistic_regression', 'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'roc_auc': 1.0}\n",
      "\n",
      "üöÄ Training linear_svm\n",
      "Metrics: {'model': 'linear_svm', 'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'roc_auc': 1.0}\n",
      "\n",
      "üöÄ Training random_forest\n",
      "Metrics: {'model': 'random_forest', 'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'roc_auc': 1.0}\n",
      "\n",
      "üöÄ Training naive_bayes\n",
      "Metrics: {'model': 'naive_bayes', 'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0, 'roc_auc': 1.0}\n",
      "\n",
      "üìä FINAL REALISTIC METRICS\n",
      "                 model  accuracy  precision  recall  f1_score  roc_auc\n",
      "0  logistic_regression       1.0        1.0     1.0       1.0      1.0\n",
      "1           linear_svm       1.0        1.0     1.0       1.0      1.0\n",
      "2        random_forest       1.0        1.0     1.0       1.0      1.0\n",
      "3          naive_bayes       1.0        1.0     1.0       1.0      1.0\n",
      "\n",
      "‚úÖ ALL MODELS TRAINED SUCCESSFULLY (NO LEAKAGE)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# PATHS\n",
    "# ======================================================\n",
    "DATA_PATH = r\"C:\\medveraxbecustom\\data\\processed\\health_misinfo_engineered_100k.csv\"\n",
    "ARTIFACT_DIR = r\"C:\\medveraxbecustom\\notebooks\\model_artifacts\"\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "\n",
    "# ======================================================\n",
    "# LOAD DATA\n",
    "# ======================================================\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"‚úÖ Loaded dataset:\", df.shape)\n",
    "\n",
    "# ======================================================\n",
    "# REMOVE LEAKY FEATURES (CRITICAL)\n",
    "# ======================================================\n",
    "LEAKY_FEATURES = [\n",
    "    \"sentiment_polarity\",\n",
    "    \"sentiment_subjectivity\",\n",
    "    \"digit_count\",\n",
    "    \"length_bucket\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=LEAKY_FEATURES)\n",
    "\n",
    "X = df.drop(columns=[\"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "# ======================================================\n",
    "# GROUP-WISE SPLIT (PREVENT TEMPLATE LEAKAGE)\n",
    "# ======================================================\n",
    "groups = df[\"text\"].str.extract(\n",
    "    r\"(acid reflux|acoustic neuroma|acetone poisoning|acute myelogenous leukemia|diabetes|cancer|asthma|covid)\",\n",
    "    expand=False\n",
    ").fillna(\"other\")\n",
    "\n",
    "gss = GroupShuffleSplit(test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "print(\"‚úÖ Group-wise split completed\")\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Test size :\", X_test.shape)\n",
    "\n",
    "# ======================================================\n",
    "# FEATURE GROUPS\n",
    "# ======================================================\n",
    "TEXT_FEATURE = \"text\"\n",
    "\n",
    "NUMERIC_FEATURES = [\n",
    "    \"char_length\",\n",
    "    \"word_count\",\n",
    "    \"exclaim_count\",\n",
    "    \"avg_word_length\"\n",
    "]\n",
    "\n",
    "# ======================================================\n",
    "# PREPROCESSORS\n",
    "# ======================================================\n",
    "standard_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text\", TfidfVectorizer(\n",
    "            max_features=20000,\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words=\"english\"\n",
    "        ), TEXT_FEATURE),\n",
    "        (\"num\", StandardScaler(), NUMERIC_FEATURES)\n",
    "    ]\n",
    ")\n",
    "\n",
    "nb_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"text\", TfidfVectorizer(\n",
    "            max_features=20000,\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words=\"english\"\n",
    "        ), TEXT_FEATURE)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# MODELS\n",
    "# ======================================================\n",
    "models = {\n",
    "    \"logistic_regression\": (\n",
    "        LogisticRegression(max_iter=4000, class_weight=\"balanced\"),\n",
    "        standard_preprocessor\n",
    "    ),\n",
    "\n",
    "    \"linear_svm\": (\n",
    "        CalibratedClassifierCV(\n",
    "            LinearSVC(class_weight=\"balanced\", max_iter=6000),\n",
    "            method=\"sigmoid\",\n",
    "            cv=3\n",
    "        ),\n",
    "        standard_preprocessor\n",
    "    ),\n",
    "\n",
    "    \"random_forest\": (\n",
    "        RandomForestClassifier(\n",
    "            n_estimators=250,\n",
    "            max_depth=20,\n",
    "            min_samples_leaf=15,\n",
    "            class_weight=\"balanced\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        standard_preprocessor\n",
    "    ),\n",
    "\n",
    "    \"naive_bayes\": (\n",
    "        MultinomialNB(),\n",
    "        nb_preprocessor\n",
    "    )\n",
    "}\n",
    "\n",
    "# ======================================================\n",
    "# TRAIN, EVALUATE, SAVE\n",
    "# ======================================================\n",
    "results = []\n",
    "\n",
    "for name, (model, preprocessor) in models.items():\n",
    "    print(f\"\\nüöÄ Training {name}\")\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    metrics = {\n",
    "        \"model\": name,\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred),\n",
    "        \"recall\": recall_score(y_test, y_pred),\n",
    "        \"f1_score\": f1_score(y_test, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_prob)\n",
    "    }\n",
    "\n",
    "    results.append(metrics)\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(\n",
    "        pipeline,\n",
    "        Path(ARTIFACT_DIR) / f\"{name}_no_leakage_model.pkl\"\n",
    "    )\n",
    "\n",
    "    # Safe printing (no rounding strings)\n",
    "    print(\"Metrics:\", {\n",
    "        k: round(v, 4) if isinstance(v, (int, float)) else v\n",
    "        for k, v in metrics.items()\n",
    "    })\n",
    "\n",
    "# ======================================================\n",
    "# SAVE METRICS SUMMARY\n",
    "# ======================================================\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\n",
    "    Path(ARTIFACT_DIR) / \"no_leakage_model_comparison.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"\\nüìä FINAL REALISTIC METRICS\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "print(\"\\n‚úÖ ALL MODELS TRAINED SUCCESSFULLY (NO LEAKAGE)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e903a711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All trained models loaded\n",
      "‚úÖ External unseen dataset created: (120, 8)\n",
      "\n",
      "üîç Evaluating logistic_regression\n",
      "{'model': 'logistic_regression', 'accuracy': 0.725, 'precision': 0.7455, 'recall': 0.6833, 'f1_score': 0.713, 'roc_auc': 0.5808}\n",
      "\n",
      "üîç Evaluating linear_svm\n",
      "{'model': 'linear_svm', 'accuracy': 0.725, 'precision': 0.7455, 'recall': 0.6833, 'f1_score': 0.713, 'roc_auc': 0.5808}\n",
      "\n",
      "üîç Evaluating random_forest\n",
      "{'model': 'random_forest', 'accuracy': 0.55, 'precision': 0.5395, 'recall': 0.6833, 'f1_score': 0.6029, 'roc_auc': 0.5572}\n",
      "\n",
      "üîç Evaluating naive_bayes\n",
      "{'model': 'naive_bayes', 'accuracy': 0.725, 'precision': 0.7455, 'recall': 0.6833, 'f1_score': 0.713, 'roc_auc': 0.6003}\n",
      "\n",
      "üìä EXTERNAL UNSEEN TEST METRICS (REAL)\n",
      "                 model  accuracy  precision  recall  f1_score  roc_auc\n",
      "0  logistic_regression     0.725     0.7455  0.6833    0.7130   0.5808\n",
      "1           linear_svm     0.725     0.7455  0.6833    0.7130   0.5808\n",
      "2        random_forest     0.550     0.5395  0.6833    0.6029   0.5572\n",
      "3          naive_bayes     0.725     0.7455  0.6833    0.7130   0.6003\n",
      "\n",
      "‚úÖ External unseen evaluation completed successfully\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# PATHS\n",
    "# ======================================================\n",
    "ARTIFACT_DIR = r\"C:\\medveraxbecustom\\notebooks\\model_artifacts\"\n",
    "\n",
    "MODEL_FILES = {\n",
    "    \"logistic_regression\": \"logistic_regression_no_leakage_model.pkl\",\n",
    "    \"linear_svm\": \"linear_svm_no_leakage_model.pkl\",\n",
    "    \"random_forest\": \"random_forest_no_leakage_model.pkl\",\n",
    "    \"naive_bayes\": \"naive_bayes_no_leakage_model.pkl\"\n",
    "}\n",
    "\n",
    "# ======================================================\n",
    "# LOAD MODELS\n",
    "# ======================================================\n",
    "models = {\n",
    "    name: joblib.load(Path(ARTIFACT_DIR) / file)\n",
    "    for name, file in MODEL_FILES.items()\n",
    "}\n",
    "\n",
    "print(\"‚úÖ All trained models loaded\")\n",
    "\n",
    "# ======================================================\n",
    "# FEATURE ENGINEERING FUNCTIONS (MUST MATCH TRAINING)\n",
    "# ======================================================\n",
    "def engineer_features(text):\n",
    "    words = re.findall(r\"\\b\\w+\\b\", text)\n",
    "    blob = TextBlob(text)\n",
    "\n",
    "    return {\n",
    "        \"char_length\": len(text),\n",
    "        \"word_count\": len(words),\n",
    "        \"exclaim_count\": text.count(\"!\"),\n",
    "        \"avg_word_length\": np.mean([len(w) for w in words]) if words else 0.0,\n",
    "        # keep polarity/subjectivity even if dropped earlier ‚Äì harmless\n",
    "        \"sentiment_polarity\": blob.sentiment.polarity,\n",
    "        \"sentiment_subjectivity\": blob.sentiment.subjectivity\n",
    "    }\n",
    "\n",
    "# ======================================================\n",
    "# CREATE TRULY UNSEEN DATA\n",
    "# ======================================================\n",
    "random.seed(99)\n",
    "\n",
    "diseases = [\n",
    "    \"migraine\", \"epilepsy\", \"thyroid disorder\",\n",
    "    \"tuberculosis\", \"parkinson disease\", \"alzheimer disease\"\n",
    "]\n",
    "\n",
    "reliable_texts = [\n",
    "    \"Medical experts state that {d} treatment depends on accurate diagnosis\",\n",
    "    \"Clinical management of {d} requires professional healthcare supervision\",\n",
    "    \"Doctors recommend long term monitoring for patients with {d}\"\n",
    "]\n",
    "\n",
    "misinfo_texts = [\n",
    "    \"{d} can be eliminated naturally without consulting doctors\",\n",
    "    \"Online sources claim {d} is easily cured using home remedies\",\n",
    "    \"Some websites suggest avoiding medical treatment for {d}\"\n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for _ in range(60):\n",
    "    t = random.choice(reliable_texts).format(d=random.choice(diseases))\n",
    "    row = {\"text\": t, \"label\": 0}\n",
    "    row.update(engineer_features(t))\n",
    "    rows.append(row)\n",
    "\n",
    "for _ in range(60):\n",
    "    t = random.choice(misinfo_texts).format(d=random.choice(diseases))\n",
    "    row = {\"text\": t, \"label\": 1}\n",
    "    row.update(engineer_features(t))\n",
    "    rows.append(row)\n",
    "\n",
    "df_unseen = pd.DataFrame(rows)\n",
    "\n",
    "print(\"‚úÖ External unseen dataset created:\", df_unseen.shape)\n",
    "\n",
    "# ======================================================\n",
    "# EVALUATE MODELS\n",
    "# ======================================================\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîç Evaluating {name}\")\n",
    "\n",
    "    X_unseen = df_unseen.drop(columns=[\"label\"])\n",
    "    y_true = df_unseen[\"label\"]\n",
    "\n",
    "    y_pred = model.predict(X_unseen)\n",
    "    y_prob = model.predict_proba(X_unseen)[:, 1]\n",
    "\n",
    "    metrics = {\n",
    "        \"model\": name,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),\n",
    "        \"f1_score\": f1_score(y_true, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_prob)\n",
    "    }\n",
    "\n",
    "    results.append(metrics)\n",
    "\n",
    "    print({k: round(v, 4) if isinstance(v, float) else v for k, v in metrics.items()})\n",
    "\n",
    "# ======================================================\n",
    "# FINAL TABLE\n",
    "# ======================================================\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nüìä EXTERNAL UNSEEN TEST METRICS (REAL)\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "results_df.to_csv(\n",
    "    Path(ARTIFACT_DIR) / \"external_unseen_model_comparison.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ External unseen evaluation completed successfully\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
